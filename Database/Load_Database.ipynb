{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3cf638e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies.\n",
    "# config.py should contain one line with the variable db_password set to a string of your PGAdmin password, for example:\n",
    "# db_password = 'Password123'\n",
    "# Do not upload config.py to a repository.\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "from config import db_password\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc9bc434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing rows 0 to 10000...Done. 29.556524753570557 total seconds elapsed.\n",
      "Importing rows 10000 to 20000...Done. 66.60185313224792 total seconds elapsed.\n",
      "Importing rows 20000 to 30000...Done. 101.349191904068 total seconds elapsed.\n",
      "Importing rows 30000 to 40000...Done. 143.67128372192383 total seconds elapsed.\n",
      "Importing rows 40000 to 50000...Done. 176.99385786056519 total seconds elapsed.\n",
      "Importing rows 50000 to 60000...Done. 223.61019897460938 total seconds elapsed.\n",
      "Importing rows 60000 to 70000...Done. 259.9621684551239 total seconds elapsed.\n",
      "Importing rows 70000 to 72210...Done. 270.21603989601135 total seconds elapsed.\n"
     ]
    }
   ],
   "source": [
    "# Connect to PostgreSQL and create a table containing the data set.\n",
    "# Import 10000 rows at a time into the database and time each set.\n",
    "\n",
    "# Database engine connection.\n",
    "db_string = f'postgresql://postgres:{db_password}@127.0.0.1:5432/Sensory_Needs_Occupational_Therapy'\n",
    "    \n",
    "# Create the database engine.\n",
    "engine = create_engine(db_string)\n",
    "    \n",
    "# Opening a connection.\n",
    "connection = engine.raw_connection()\n",
    "    \n",
    "# Creating a cursor object using the cursor() method.\n",
    "cursor = connection.cursor()\n",
    "    \n",
    "# Dropping the table if it already exists.\n",
    "cursor.execute('DROP TABLE IF EXISTS NSCH_Data')\n",
    "    \n",
    "# Commit changes in the database.\n",
    "connection.commit()\n",
    "    \n",
    "# Close the connection.\n",
    "connection.close()\n",
    "    \n",
    "# Import data to SQL using chunksize parameter\n",
    "# Create a variable for the number of rows imported.\n",
    "rows_imported = 0\n",
    "    \n",
    "# Create the start time variable.\n",
    "start_time = time.time()\n",
    "for data in pd.read_csv(f'../data/Main_Sean_File_Numeric_2019-2020 NSCH_Topical_CAHMI_DRC_1920.csv', chunksize=10000):\n",
    "        \n",
    "    # Print the range of rows being imported.\n",
    "    print(f'Importing rows {rows_imported} to {rows_imported + len(data)}...', end='')\n",
    "    data.to_sql(name='NSCH_Data', con=engine, if_exists='append')\n",
    "        \n",
    "    # Increase the number of rows imported by the chunksize.\n",
    "    rows_imported += len(data)\n",
    "        \n",
    "    # Print that the rows have finished importing and add the elapsed time to final print out.\n",
    "    print(f'Done. {time.time() - start_time} total seconds elapsed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe6c517",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
