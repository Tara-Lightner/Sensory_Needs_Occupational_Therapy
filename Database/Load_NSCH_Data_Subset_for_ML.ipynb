{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a07885ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies.\n",
    "# config.py should contain one line with the variable db_password set to a string of your PGAdmin password, for example:\n",
    "# db_password = 'Password123'\n",
    "# Do not upload config.py to a repository.\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "from config import db_password\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1702207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing rows 0 to 10000...Done. 1.04848051071167 total seconds elapsed.\n",
      "Importing rows 10000 to 20000...Done. 1.8098032474517822 total seconds elapsed.\n",
      "Importing rows 20000 to 30000...Done. 2.5523593425750732 total seconds elapsed.\n",
      "Importing rows 30000 to 40000...Done. 3.3438868522644043 total seconds elapsed.\n",
      "Importing rows 40000 to 50000...Done. 4.101232528686523 total seconds elapsed.\n",
      "Importing rows 50000 to 60000...Done. 4.8527350425720215 total seconds elapsed.\n",
      "Importing rows 60000 to 70000...Done. 5.641119956970215 total seconds elapsed.\n",
      "Importing rows 70000 to 72210...Done. 5.823818206787109 total seconds elapsed.\n"
     ]
    }
   ],
   "source": [
    "# Load data into PostgreSQL database.\n",
    "\n",
    "# Database engine connection.\n",
    "db_string = f'postgresql://postgres:{db_password}@127.0.0.1:5432/Sensory_Needs_Occupational_Therapy'\n",
    "    \n",
    "# Create the database engine.\n",
    "engine = create_engine(db_string)\n",
    "    \n",
    "# Opening a connection.\n",
    "connection = engine.raw_connection()\n",
    "    \n",
    "# Creating a cursor object using the cursor() method.\n",
    "cursor = connection.cursor()\n",
    "    \n",
    "# Dropping the table if it already exists.\n",
    "cursor.execute('DROP TABLE IF EXISTS NSCH_Data_ML_Subset')\n",
    "    \n",
    "# Commit changes in the database.\n",
    "connection.commit()\n",
    "    \n",
    "# Close the connection.\n",
    "connection.close()\n",
    "    \n",
    "# Import data to SQL using chunksize parameter\n",
    "# Create a variable for the number of rows imported.\n",
    "rows_imported = 0\n",
    "    \n",
    "# Create the start time variable.\n",
    "start_time = time.time()\n",
    "for data in pd.read_csv(f'../data/NSCH_Data_ML_Subset.csv', chunksize=10000):\n",
    "        \n",
    "    # Print the range of rows being imported.\n",
    "    print(f'Importing rows {rows_imported} to {rows_imported + len(data)}...', end='')\n",
    "    data.to_sql(name='NSCH_Data_ML_Subset', con=engine, if_exists='append')\n",
    "        \n",
    "    # Increase the number of rows imported by the chunksize.\n",
    "    rows_imported += len(data)\n",
    "        \n",
    "    # Print that the rows have finished importing and add the elapsed time to final print out.\n",
    "    print(f'Done. {time.time() - start_time} total seconds elapsed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5318eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
